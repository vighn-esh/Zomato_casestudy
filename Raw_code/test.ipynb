{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in restaurant_dimension_table: 107380\n",
      "Total rows in fact_table: 107380\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "sqlite_db_path = \"Main_DB/zomato_DB.sqlite\"\n",
    "engine = sqlalchemy.create_engine(f'sqlite:///{sqlite_db_path}')\n",
    "\n",
    "def count_rows_in_table(engine, table_name):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "        row_count = result.fetchone()[0]\n",
    "        print(f\"Total rows in {table_name}: {row_count}\")\n",
    "\n",
    "def save_table_to_csv(engine, table_name, output_file):\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Table {table_name} saved to {output_file}\")\n",
    "\n",
    "\n",
    "count_rows_in_table(engine, 'restaurant_dimension_table')\n",
    "count_rows_in_table(engine, 'location_dimension_table')\n",
    "count_rows_in_table(engine, 'fact_table')\n",
    "\n",
    "\n",
    "save_table_to_csv(engine, 'restaurant_dimension_table', 'restaurant_dimension_table.csv')\n",
    "save_table_to_csv(engine, 'fact_table', 'fact_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while reading the config file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 15:40:57,325 - INFO - Starting ETL and Predictive Analysis Pipeline...\n",
      "2024-09-18 15:40:57,329 - INFO - Database created and connected successfully.\n",
      "2024-09-18 15:40:57,330 - INFO - Starting Predictive Analysis...\n",
      "2024-09-18 15:40:58,261 - INFO - Linear Regression - MSE: 0.11314048336203299, MAE: 0.2424909704035927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in DataFrame: Index(['NAME', 'PRICE', 'CUSINE_CATEGORY', 'CITY', 'REGION', 'URL', 'PAGENO',\n",
      "       'CUSINETYPE', 'TIMING', 'RATING_TYPE', 'RATING', 'VOTES', 'Latitude',\n",
      "       'Longitude'],\n",
      "      dtype='object')\n",
      "Available columns in DataFrame: Index(['NAME', 'PRICE', 'CUSINE_CATEGORY', 'CITY', 'REGION', 'URL', 'PAGENO',\n",
      "       'CUSINETYPE', 'TIMING', 'RATING_TYPE', 'RATING', 'VOTES', 'Latitude',\n",
      "       'Longitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Opening'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27960\\3902883023.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0mlr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictive_analysis_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predictive analysis completed successfully.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0metl_predictive_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27960\\3902883023.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'sqlite:///{sqlite_db_path}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0minitialize_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;31m# Predictive Analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mlr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictive_analysis_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predictive analysis completed successfully.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27960\\3902883023.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(engine, config)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# Load and split data for Decision Tree (including categorical columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mX_train_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_and_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"staging_data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_numerical_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m# Train Decision Tree model for classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mdt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'criterion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[1;31m# Evaluate Decision Tree model for classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0maccuracy_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_classification_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Decision Tree - Accuracy: {accuracy_dt}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27960\\3902883023.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X_train, y_train, max_depth, criterion)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"\"\"Train a Decision Tree model for classification.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \"\"\"\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         super()._fit(\n\u001b[0m\u001b[0;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    238\u001b[0m             check_X_params = dict(\n\u001b[0;32m    239\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             )\n\u001b[0;32m    241\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    243\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             )\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    613\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    912\u001b[0m                         )\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m                 raise ValueError(\n\u001b[0;32m    918\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vighnesh.ak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Opening'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "config = read_config('PA_config.yml')\n",
    "\n",
    "def initialize_db(engine):\n",
    "    \"\"\"Check connection and create the database if necessary.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        logging.info(\"Database created and connected successfully.\")\n",
    "\n",
    "def train_linear_regression(X_train, y_train):\n",
    "    \"\"\"Train a Linear Regression model.\"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_decision_tree(X_train, y_train, max_depth, criterion):\n",
    "    \"\"\"Train a Decision Tree model for classification.\"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_regression_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate a regression model with Mean Squared Error and Mean Absolute Error.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return mse, mae\n",
    "\n",
    "\n",
    "def label_encode_categorical_features(df, categorical_columns):\n",
    "    \"\"\"Apply Label Encoding to categorical columns.\"\"\"\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))  # Encode categorical column\n",
    "    return df  # Only return the DataFrame\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_classification_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate a classification model with Accuracy.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean data by replacing non-numeric values like '-' with NaN and handle missing values.\"\"\"\n",
    "    df.replace('-', np.nan, inplace=True)  # Replace '-' with NaN\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)  # Handle missing values using median\n",
    "    return df\n",
    "\n",
    "def load_and_prepare_data(engine, table_name, selected_columns, use_numerical_only=False):\n",
    "    \"\"\"Load and prepare data for modeling from the database.\"\"\"\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Clean the data\n",
    "    df = clean_data(df)\n",
    "    print(\"Available columns in DataFrame:\", df.columns)\n",
    "\n",
    "    # If using numerical columns only (for Linear Regression)\n",
    "    if use_numerical_only:\n",
    "        numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        selected_columns = [col for col in selected_columns if col in numerical_columns]\n",
    "\n",
    "    # If not using numerical only, we will label encode the categorical columns for Decision Tree\n",
    "    if not use_numerical_only:\n",
    "        categorical_columns = ['CUSINETYPE', 'RATING_TYPE', 'CITY']\n",
    "        df= label_encode_categorical_features(df, categorical_columns)\n",
    "\n",
    "    # Split into features and target\n",
    "    X = df[selected_columns]\n",
    "    y = df['RATING']\n",
    "\n",
    "    # For Decision Tree Classification: round ratings to nearest integer\n",
    "    y_class = y.round().astype(int)\n",
    "\n",
    "    return train_test_split(X, y, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def predictive_analysis_pipeline(engine, config):\n",
    "    logging.info(\"Starting Predictive Analysis...\")\n",
    "\n",
    "    # Columns to be used for prediction\n",
    "    selected_columns = config['columns']['selected_features']\n",
    "\n",
    "    # Load and split data for Linear Regression (numerical columns only)\n",
    "    X_train_lr, X_test_lr, y_train_lr, y_test_lr, _, _ = load_and_prepare_data(engine, \"staging_data\", selected_columns, use_numerical_only=True)\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    lr_model = train_linear_regression(X_train_lr, y_train_lr)\n",
    "    # Evaluate Linear Regression model\n",
    "    mse_lr, mae_lr = evaluate_regression_model(lr_model, X_test_lr, y_test_lr)\n",
    "    logging.info(f\"Linear Regression - MSE: {mse_lr}, MAE: {mae_lr}\")\n",
    "\n",
    "    # Load and split data for Decision Tree (including categorical columns)\n",
    "    X_train_dt, X_test_dt, y_train_dt, y_test_dt, y_train_class, y_test_class = load_and_prepare_data(engine, \"staging_data\", selected_columns, use_numerical_only=False)\n",
    "\n",
    "    # Train Decision Tree model for classification\n",
    "    dt_model = train_decision_tree(X_train_dt, y_train_class, config['DT']['max_depth'], config['DT']['criterion'])\n",
    "    # Evaluate Decision Tree model for classification\n",
    "    accuracy_dt = evaluate_classification_model(dt_model, X_test_dt, y_test_class)\n",
    "    logging.info(f\"Decision Tree - Accuracy: {accuracy_dt}\")\n",
    "\n",
    "    return lr_model, dt_model\n",
    "\n",
    "def etl_predictive_pipeline():\n",
    "    logging.info(\"Starting ETL and Predictive Analysis Pipeline...\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = read_config('PA_config.yml')\n",
    "\n",
    "    # Set up database connection\n",
    "    sqlite_db_path = config['database']['sqlite_db_path']\n",
    "    os.makedirs(os.path.dirname(sqlite_db_path), exist_ok=True)\n",
    "    engine = sqlalchemy.create_engine(f'sqlite:///{sqlite_db_path}')\n",
    "    initialize_db(engine)\n",
    "\n",
    "    # Predictive Analysis\n",
    "    lr_model, dt_model = predictive_analysis_pipeline(engine, config)\n",
    "    logging.info(\"Predictive analysis completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_predictive_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 26) (570727082.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    load_and_prepare_data(engine,staging\")\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 26)\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_data(engine, table_name, selected_columns):\n",
    "    \"\"\"Load and prepare data for modeling from the database.\"\"\"\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Print available columns for debugging\n",
    "    print(\"Available columns in the DataFrame:\", df.columns)\n",
    "\n",
    "    # Clean the data\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # List of categorical columns to encode\n",
    "    categorical_columns = ['CUSINETYPE', 'RATING_TYPE', 'CITY']\n",
    "\n",
    "    # Apply One-Hot Encoding\n",
    "    df = encode_categorical_features(df, categorical_columns)\n",
    "\n",
    "    # Split into features and target\n",
    "    X = df[selected_columns]\n",
    "    y = df['RATING']\n",
    "\n",
    "    # For Decision Tree Classification: round ratings to nearest integer\n",
    "    y_class = y.round().astype(int)\n",
    "\n",
    "    return train_test_split(X, y, y_class, test_size=0.2, random_state=42)\n",
    "load_and_prepare_data(engine,\"staging_data\",selected_columns=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the 'staging_data' table:\n",
      "               name\n",
      "0              NAME\n",
      "1             PRICE\n",
      "2   CUSINE_CATEGORY\n",
      "3              CITY\n",
      "4            REGION\n",
      "5               URL\n",
      "6            PAGENO\n",
      "7        CUSINETYPE\n",
      "8            TIMING\n",
      "9       RATING_TYPE\n",
      "10           RATING\n",
      "11            VOTES\n",
      "12         Latitude\n",
      "13        Longitude\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "\n",
    "# Set up database connection\n",
    "sqlite_db_path = \"../Main_DB/zomato_DB.sqlite\"\n",
    "engine = sqlalchemy.create_engine(f'sqlite:///{sqlite_db_path}')\n",
    "\n",
    "# Query to retrieve the table schema\n",
    "def check_table_columns(engine, table_name):\n",
    "    \"\"\"Retrieve and print the column names of a given table.\"\"\"\n",
    "    query = f\"PRAGMA table_info({table_name})\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"Column names in the '{table_name}' table:\")\n",
    "    print(df[['name']])  # 'name' column contains the column names in the table\n",
    "\n",
    "# Call the function to check the columns in the 'staging_data' table\n",
    "check_table_columns(engine, 'staging_data')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
